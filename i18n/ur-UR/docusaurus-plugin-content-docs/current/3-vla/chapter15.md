---
id: chapter15
title: Module-3.vla-chapter-15
sidebar_position: 3
slug: /vla/chapter15
---

# باب 15: بصری گراؤنڈنگ اور ایمبوڈیڈ پرسیپشن

کسی روبوٹ کے لیے قدرتی زبان کی ہدایات کو صحیح معنوں میں سمجھنے اور ان پر عمل کرنے کے لیے، اسے لسانی تصورات کو اپنی حسی پرسیپشنز سے **بصری طور پر جوڑنے** کے قابل ہونا چاہیے۔ اس کا مطلب ہے کہ \"سرخ کیوب،\" \"میز کے بائیں طرف،\" یا \"ہینڈل کو پکڑو\" جیسے الفاظ اور جملوں کو اس کے بصری میدان میں مخصوص پکسلز، اشیاء، اور مقامی تعلقات سے جوڑنا۔ یہ عمل VLA سسٹمز کے اندر ایمبوڈیڈ پرسیپشن کا مرکز ہے۔

## بصری گراؤنڈنگ کیا ہے؟

بصری گراؤنڈنگ قدرتی زبان کے عناصر (الفاظ، جملے، فقرے) کو کسی تصویر یا ویڈیو میں متعلقہ علاقوں یا اشیاء سے جوڑنے کا کام ہے۔ یہ روبوٹس کے لیے بہت اہم ہے کیونکہ:

*   **ابہام کو حل کرنا**: زبان مبہم ہو سکتی ہے۔ \"بلاک اٹھاؤ\" کے لیے روبوٹ کو بصری طور پر یہ شناخت کرنے کی ضرورت ہے کہ *کون سا* بلاک ہے۔
*   **عمل کو فعال کرنا**: ایک بار جب کسی چیز کو بصری طور پر گراؤنڈ کر دیا جاتا ہے، تو روبوٹ اس کا پوز شمار کر سکتا ہے، پکڑنے کی منصوبہ بندی کر سکتا ہے، اور جسمانی عمل کو انجام دے سکتا ہے۔
*   **مظاہروں سے سیکھنا**: جب کوئی انسان \"یہ کرو\" کہتا ہے اور اشارہ کرتا ہے، تو بصری گراؤنڈنگ روبوٹ کو یہ سمجھنے میں مدد کرتی ہے کہ \"یہ\" کس چیز سے مراد ہے۔

### بصری گراؤنڈنگ کی اقسام

*   **آبجیکٹ گراؤنڈنگ (Object Grounding)**: آبجیکٹ کے اسموں (مثلاً، \"کپ،\" \"کی بورڈ\") کو ان کی بصری مثالوں سے جوڑنا۔
*   **ایٹریبیوٹ گراؤنڈنگ (Attribute Grounding)**: صفتوں (مثلاً، \"سرخ،\" \"چمکدار،\" \"بڑا\") کو بصری خصوصیات سے جوڑنا۔
*   **ریلیشنل گراؤنڈنگ (Relational Grounding)**: مقامی حروفِ جر (مثلاً، \"پر،\" \"کے نیچے،\" \"کے ساتھ\") کو اشیاء کے درمیان مقامی تعلقات سے جوڑنا۔
*   **ایکشن گراؤنڈنگ (Action Grounding)**: فعلوں (مثلاً، \"پکڑنا،\" \"دھکیلنا،\" \"انڈیلنا\") کو مشاہدہ شدہ اعمال یا پیش گوئی شدہ افورڈنس سے جوڑنا۔

## بصری گراؤنڈنگ کی تکنیکیں

جدید بصری گراؤنڈنگ تکنیکیں اکثر کمپیوٹر ویژن اور قدرتی زبان کی پروسیسنگ میں پیشرفت کو یکجا کرتی ہیں:

1.  **آبجیکٹ ڈیٹیکشن اور سیگمنٹیشن (Object Detection and Segmentation)**: آف-دی-شیلف آبجیکٹ ڈیٹیکٹرز (مثلاً، YOLO، Mask R-CNN) عام اشیاء کی شناخت اور لوکلائز کر سکتے ہیں۔ VLA ماڈلز پھر ان ڈیٹیکٹ شدہ اشیاء کو لسانی تذکروں سے جوڑ سکتے ہیں۔
2.  **ویژن-لینگویج ماڈلز (VLMs)**: یہ ماڈلز تصاویر اور متعلقہ متنی تفصیلات (مثلاً، امیج کیپشنز) کے بڑے ڈیٹا سیٹس پر مشترکہ طور پر تربیت یافتہ ہوتے ہیں۔ وہ بصری خصوصیات کو لسانی تصورات سے جوڑنا سیکھتے ہیں۔ مثالوں میں CLIP، ALIGN، اور Flamingo شامل ہیں۔
3.  **کراس-موڈل اٹینشن (Cross-Modal Attention)**: وہ طریقہ کار جو ایک لینگویج ماڈل کو کسی استفسار کو پروسیس کرتے وقت کسی تصویر کے متعلقہ حصوں پر \"توجہ دینے\" کی اجازت دیتے ہیں، اور اس کے برعکس۔ یہ ایک متنی فقرے کے بصری حوالہ کو درست طریقے سے بیان کرنے میں مدد کرتا ہے۔
4.  **ریفرنگ ایکسپریشن کمپری ہینشن (Referring Expression Comprehension)**: ایک تصویر اور ایک قدرتی زبان کا فقرہ دیا گیا ہے، مقصد یہ ہے کہ بیان کردہ چیز کے مطابق باؤنڈنگ باکس یا ماسک کو آؤٹ پٹ کیا جائے۔
5.  **ایمبوڈیڈ AI ڈیٹا سیٹس (Embodied AI Datasets)**: CLEVR، ReferItGame، اور اکثر Isaac Sim جیسے سمیلیٹروں سے اپنی مرضی کے مطابق مصنوعی ڈیٹا سیٹ، تربیت کے لیے بھرپور بصری-لسانی جوڑے فراہم کرتے ہیں۔

## ایمبوڈیڈ پرسیپشن: جامد تصاویر سے آگے

ایمبوڈیڈ پرسیپشن سنگل، جامد تصاویر میں گراؤنڈنگ سے آگے بڑھتا ہے۔ یہ روبوٹ کی اپنے ماحول کو *جب وہ اس کے ساتھ تعامل کرتا ہے* تو اسے دیکھنے اور سمجھنے کی صلاحیت سے مراد ہے۔ اس میں شامل ہیں:

*   **ایکٹو پرسیپشن (Active Perception)**: روبوٹ جان بوجھ کر اپنے سینسرز (مثلاً، کیمرہ پین/ٹلٹ، روبوٹ بیس کی حرکت) کو حرکت دیتا ہے تاکہ بہتر نظارے حاصل کر سکے یا ابہام کو حل کر سکے۔
*   **پرسیپشن-ایکشن لوپس (Perception-Action Loops)**: روبوٹ کی پرسیپشن اس کے اعمال کو مطلع کرتی ہے، اور اس کے اعمال، بدلے میں، اس کے مستقبل کے پرسیپشنز کو متاثر کرتے ہیں۔
*   **اسٹیٹ ایسٹیمیشن (State Estimation)**: آنے والے سینسر ڈیٹا کی بنیاد پر دنیا کے اپنے اندرونی ماڈل (مثلاً، اشیاء کے مقامات، خصوصیات، روبوٹ پوز) کو مسلسل اپ ڈیٹ کرنا۔
*   **پروپریوسیپشن (Proprioception)**: اپنے جسم کی حالت اور ماحول کے ساتھ تعامل کو سمجھنے کے لیے اندرونی سینسر ڈیٹا (مثلاً، جوائنٹ اینگلز، فورس/ٹارک سینسرز) کو شامل کرنا۔

### ایمبوڈیڈ پرسیپشن سیکھنا

*   **رینفورسمنٹ لرننگ (RL)**: روبوٹس نقلی ماحول میں آزمائش اور غلطی کے ذریعے بہترین پرسیپشن کی حکمت عملی سیکھ سکتے ہیں، جہاں انعام کا فنکشن مؤثر بصری گراؤنڈنگ اور کام کی تکمیل کی حوصلہ افزائی کرتا ہے۔
*   **ایمی ٹیشن لرننگ/لرننگ فرام ڈیمونسٹریشن (LfD)**: روبوٹس انسانی مظاہروں کا مشاہدہ کرتے ہیں، جہاں انسانی اعمال ضمنی طور پر ان کے بصری سیاق و سباق میں گراؤنڈ ہوتے ہیں۔ روبوٹ ان گراؤنڈڈ طرز عمل کی نقل کرنا سیکھتا ہے۔
*   **مصنوعی ڈیٹا اور سم-ٹو-ریئل (Synthetic Data and Sim-to-Real)**: Isaac Sim جیسے سمیلیٹروں میں بہترین گراؤنڈ-ٹروتھ تشریحات کے ساتھ متنوع مصنوعی ڈیٹا تیار کرنا مضبوط پرسیپشن ماڈلز کی تربیت کے لیے اہم ہے جو پھر حقیقی دنیا میں منتقل ہو سکتے ہیں۔

اس باب نے زبان کو روبوٹ کی حسی دنیا سے جوڑنے میں بصری گراؤنڈنگ کی اہمیت کو اجاگر کیا ہے اور ایمبوڈیڈ پرسیپشن کے تصور کو متعارف کرایا ہے۔ بصری معلومات کو لسانی سمجھ کے ساتھ مؤثر طریقے سے فیوز کرکے، روبوٹ اپنے ماحول کی گہری اور زیادہ قابل عمل سمجھ حاصل کر سکتے ہیں۔ اگلے باب میں، ہم یہ دیکھیں گے کہ یہ پرسیپشنز مختلف کنٹرول پالیسیوں کے ذریعے جسمانی اعمال میں کیسے ترجمہ ہوتی ہیں۔